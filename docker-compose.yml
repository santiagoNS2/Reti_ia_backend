services:
  web:
    build: .
    container_name: web
    ports:
      - "8000:8000"
    volumes:
      - ./app:/app
      - ./archivos:/archivos
    environment:
      - OLLAMA_URL=http://ollama:11434
  
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ~/.ollama:/root/.ollama
    tty: true

  ollama_loader:
    image: curlimages/curl:latest
    depends_on:
      - ollama
    entrypoint: >
      sh -c "
        echo ' Esperando que Ollama est√© listo...';
        until curl -s http://ollama:11434; do sleep 2; done;
        echo ' Lanzando modelo mistral...';
        curl -X POST http://ollama:11434/api/generate -d '{\"model\": \"mistral\", \"prompt\": \"Hola\"}'
      "
      
volumes:
  ollama_models:

